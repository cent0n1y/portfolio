{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "PqC4R7SGseKa"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0J2RM8f5wP33"
      },
      "source": [
        "## 2.1 Создание нейронов и полносвязных слоев"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2ArJn_nsdZC"
      },
      "source": [
        "2.1.1. Используя операции над матрицами и векторами из библиотеки `torch`, реализовать нейрон с заданными весами `weights` и `bias`. Прогнать вектор `inputs` через нейрон и вывести результат."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "f4agkY9WqPwe"
      },
      "outputs": [],
      "source": [
        "class Neuron:\n",
        "  def __init__(self, weights, bias):\n",
        "    self.w = weights\n",
        "    self.b=bias\n",
        "\n",
        "\n",
        "  def forward(self, inputs):\n",
        "    y_pred = self.w @ inputs + self.b\n",
        "    return y_pred # <реализовать логику нейрона>\n",
        "  #y_pred = torch.mv(inputs.view(1,-1), self.w.view(-1,1))+self.b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "HJRkSkHHsb7u"
      },
      "outputs": [],
      "source": [
        "inputs = torch.tensor([1.0, 2.0, 3.0, 4.0])\n",
        "weights = torch.tensor([-0.2, 0.3, -0.5, 0.7])\n",
        "bias = 3.14\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n1 = Neuron(weights, bias)\n",
        "y = n1.forward(inputs)\n",
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0zKJMEhv4X9h",
        "outputId": "17d49ba7-0b31-4224-8134-436f2b7a9e64"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(4.8400)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qJvnwiyty37"
      },
      "source": [
        "2.1.2 Используя операции над матрицами и векторами из библиотеки `torch`, реализовать полносвязный слой с заданными весами `weights` и `biases`. Прогнать вектор `inputs` через слой и вывести результат."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "fVWF3a9vtx90"
      },
      "outputs": [],
      "source": [
        "class Linear:\n",
        "  def __init__(self, weights, biases):\n",
        "    # <создать атрибуты объекта weights и biases>\n",
        "    self.ws = weights\n",
        "    self.bs =bias\n",
        "    pass\n",
        "\n",
        "  def forward(self, inputs):\n",
        "    y_pred = torch.mm (inputs.view(1,-1),self.ws)+ self.bs\n",
        "    return y_pred # <реализовать логику слоя>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Fo-JFnHPuFCS"
      },
      "outputs": [],
      "source": [
        "inputs = torch.tensor([1.0, 2.0, 3.0, 4.0])\n",
        "weights = torch.tensor([[-0.2, 0.3, -0.5, 0.7],\n",
        "                        [0.5, -0.91, 0.26, -0.5],\n",
        "                        [-0.26, -0.27, 0.17, 0.87]]).T\n",
        "\n",
        "biases = torch.tensor([3.14, 2.71, 7.2])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "l1 = Linear(weights, biases)\n",
        "y = l1.forward(inputs)\n",
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X20NQ1pR9VgT",
        "outputId": "59516b5c-21b2-48ae-ddc8-13fa84f58143"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[4.8400, 0.6000, 6.3300]])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQtsJzcxuyGd"
      },
      "source": [
        "2.1.3 Реализовать полносвязный слой из __2.1.2__ таким образом, чтобы он мог принимать на вход матрицу (батч) с данными. Продемонстрировать работу.\n",
        "Результатом прогона сквозь слой должна быть матрица размера `batch_size` x `n_neurons`.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Linear:\n",
        "  def __init__(self, batch_size,weights, biases):\n",
        "    # <создать атрибуты объекта weights и biases>\n",
        "    self.ws = weights\n",
        "    self.bs =bias\n",
        "    self.batch = batch_size\n",
        "    pass\n",
        "\n",
        "  def forward(self, inputs):\n",
        "    y_pred = torch.mm (inputs.view(batch_size,-1),self.ws)+ self.bs\n",
        "    return y_pred # <реализовать логику слоя>"
      ],
      "metadata": {
        "id": "LcY_TCf3CDpw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z8IizmtsuhO1"
      },
      "outputs": [],
      "source": [
        "inputs = torch.tensor([[1, 2, 3, 2.5],\n",
        "                       [2, 5, -1, 2],\n",
        "                       [-1.5, 2.7, 3.3, -0.8]])\n",
        "batch_size= inputs.size()[0]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "l1 = Linear(batch_size,weights,biases)\n",
        "y = l1.forward(inputs)\n",
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PhtclbjX_o4D",
        "outputId": "05399c5c-fa4c-45d8-b5af-ad8279347aaf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 3.7900,  1.3500,  5.0250],\n",
              "        [ 6.1400, -1.6700,  2.8400],\n",
              "        [ 2.0400,  1.1910,  2.6660]])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQ2OxH4_vBLu"
      },
      "source": [
        "2.1.4 Используя операции над матрицами и векторами из библиотеки `torch`, реализовать полносвязный слой из `n_neurons` нейронов с `n_features` весами у каждого нейрона (инициализируются из стандартного нормального распределения). Прогнать вектор `inputs` через слой и вывести результат. Результатом прогона сквозь слой должна быть матрица размера `batch_size` x `n_neurons`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "IOv52EdovASs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24cef86d-13f5-4555-87d9-11f024263598"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.8398,  0.6193,  1.2870],\n",
            "        [ 1.2931,  2.1635, -0.4976],\n",
            "        [-0.4707,  1.2225,  0.3305],\n",
            "        [-1.0365,  0.9047, -0.5361]])\n",
            "tensor([-1.2293, -1.7727,  0.2837])\n"
          ]
        }
      ],
      "source": [
        "class Linear:\n",
        "  def __init__(self, n_features, n_neurons):\n",
        "    # <создать атрибуты объекта weights и biases>\n",
        "    self.ws = torch.randn(n_features,n_neurons)\n",
        "    self.bs =torch.randn(n_neurons)\n",
        "    print(self.ws)\n",
        "    print(self.bs)\n",
        "\n",
        "\n",
        "  def forward(self, inputs):\n",
        "    return torch.matmul(inputs, self.weights) + self.biases# <реализовать логику слоя>\n",
        "\n",
        "n_features = 4\n",
        "n_neurons = 3\n",
        "batch_size = 2\n",
        "\n",
        "linear_layer = Linear(n_features, n_neurons)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uc7-dIxyEueM",
        "outputId": "c614822a-bc93-4600-996f-52a5e8fd5372"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-1.0286, -0.1512, -2.0541],\n",
            "        [-0.3385, -0.2796,  0.7984],\n",
            "        [-0.7742, -1.7689,  0.9328],\n",
            "        [-0.2104, -1.1546, -0.5398]])\n",
            "tensor([1.1965, 1.4649, 1.3903])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IPG4UqL4wajI"
      },
      "source": [
        "2.1.5 Используя решение из __2.1.4__, создать 2 полносвязных слоя и пропустить матрицу `inputs` последовательно через эти два слоя. Количество нейронов в первом слое выбрать произвольно, количество нейронов во втором слое выбрать так, чтобы результатом прогона являлась матрица (3x7)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RjjQIQlTxJE6"
      },
      "outputs": [],
      "source": [
        "inputs = torch.tensor([[1, 2, 3, 2.5],\n",
        "                       [2, 5, -1, 2],\n",
        "                       [-1.5, 2.7, 3.3, -0.8]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cRVH_2K7xTBC"
      },
      "source": [
        "## 2.2 Создание функций активации"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B9kngE6Fxs9D"
      },
      "source": [
        "2.2.1 Используя операции над матрицами и векторами из библиотеки `torch`, реализовать функцию активации ReLU:\n",
        "\n",
        "![](https://wikimedia.org/api/rest_v1/media/math/render/svg/f4353f4e3e484130504049599d2e7b040793e1eb)\n",
        "\n",
        "Создать матрицу размера (4,3), заполненную числами из стандартного нормального распределения, и проверить работоспособность функции активации."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "jZLvMRByxSTC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "560d5e16-10b6-48f3-b982-c1f6805092cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Исходные данные:\n",
            "tensor([[-1.1364, -0.5351,  1.3897],\n",
            "        [ 0.3717,  1.6984,  0.4100],\n",
            "        [ 0.2511,  0.2431, -1.1149],\n",
            "        [-1.2264, -0.1825,  0.4658]])\n",
            "Результат ReLU:\n",
            "tensor([[0.0000, 0.0000, 1.3897],\n",
            "        [0.3717, 1.6984, 0.4100],\n",
            "        [0.2511, 0.2431, 0.0000],\n",
            "        [0.0000, 0.0000, 0.4658]])\n"
          ]
        }
      ],
      "source": [
        "class ReLU:\n",
        "    def forward(self, inputs):\n",
        "        # Применяем функцию активации ReLU к входным данным\n",
        "        return torch.max(torch.zeros_like(inputs), inputs)\n",
        "\n",
        "relu = ReLU()\n",
        "\n",
        "inputs = torch.randn(4, 3)  # Пример матрицы размера (4, 3) с данными из стандартного нормального распределения\n",
        "output = relu.forward(inputs)\n",
        "\n",
        "print(\"Исходные данные:\")\n",
        "print(inputs)\n",
        "print(\"Результат ReLU:\")\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "puExCWiKyTtb"
      },
      "source": [
        "2.2.2 Используя операции над матрицами и векторами из библиотеки `torch`, реализовать функцию активации softmax:\n",
        "\n",
        "![](https://wikimedia.org/api/rest_v1/media/math/render/svg/6d7500d980c313da83e4117da701bf7c8f1982f5)\n",
        "\n",
        "Создать матрицу размера (4,3), заполненную числами из стандартного нормального распределения, и проверить работоспособность функции активации. Строки матрицы трактовать как выходы линейного слоя некоторого классификатора для 4 различных примеров."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "fXNcFlqqyKHl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f17f99cf-9bb1-43aa-8497-9c38ab2b0960"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Исходные данные:\n",
            "tensor([[-1.2650,  1.4443, -1.6843],\n",
            "        [ 0.0258,  0.3896,  0.2775],\n",
            "        [ 1.1011, -1.8096, -1.1325],\n",
            "        [-0.3373,  0.4029,  1.3477]])\n",
            "Результат Softmax:\n",
            "tensor([[0.0600, 0.9006, 0.0394],\n",
            "        [0.2685, 0.3863, 0.3453],\n",
            "        [0.8609, 0.0469, 0.0922],\n",
            "        [0.1178, 0.2470, 0.6352]])\n"
          ]
        }
      ],
      "source": [
        "class Softmax:\n",
        "    def forward(self, inputs):\n",
        "        exp_inputs = torch.exp(inputs - torch.max(inputs, dim=1, keepdim=True).values)\n",
        "        softmax_output = exp_inputs / exp_inputs.sum(dim=1, keepdim=True)\n",
        "        return softmax_output\n",
        "softmax = Softmax()\n",
        "\n",
        "inputs = torch.randn(4, 3)\n",
        "output = softmax.forward(inputs)\n",
        "\n",
        "print(\"Исходные данные:\")\n",
        "print(inputs)\n",
        "print(\"Результат Softmax:\")\n",
        "print(output)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vxVK2TYez_Ye"
      },
      "source": [
        "2.2.3 Используя операции над матрицами и векторами из библиотеки `torch`, реализовать функцию активации ELU:\n",
        "\n",
        "![](https://wikimedia.org/api/rest_v1/media/math/render/svg/eb23becd37c3602c4838e53f532163279192e4fd)\n",
        "\n",
        "Создать матрицу размера (4,3), заполненную числами из стандартного нормального распределения, и проверить работоспособность функции активации."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "NzMz7HDLySxK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11e021c4-cb85-40d8-d22a-4d2b6a6c24f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Исходные данные:\n",
            "tensor([[-0.7719,  0.1027, -0.3688],\n",
            "        [ 0.2679, -0.3910, -0.2987],\n",
            "        [-0.1298,  1.3086,  0.2821],\n",
            "        [-1.8904,  0.2318, -0.8955]])\n",
            "Результат ELU:\n",
            "tensor([[-0.5379,  0.1027, -0.3084],\n",
            "        [ 0.2679, -0.3236, -0.2582],\n",
            "        [-0.1217,  1.3086,  0.2821],\n",
            "        [-0.8490,  0.2318, -0.5916]])\n"
          ]
        }
      ],
      "source": [
        "\n",
        "class ELU:\n",
        "  def __init__(self, alpha):\n",
        "     self.alpha = alpha\n",
        "\n",
        "  def forward(self, inputs):\n",
        "    return torch.where(inputs > 0, inputs, self.alpha * (torch.exp(inputs) - 1))\n",
        "\n",
        "elu_activation = ELU(alpha=1.0)\n",
        "\n",
        "inputs = torch.randn(4, 3)\n",
        "output = elu_activation.forward(inputs)\n",
        "\n",
        "print(\"Исходные данные:\")\n",
        "print(inputs)\n",
        "print(\"Результат ELU:\")\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0peh8r-20Pof"
      },
      "source": [
        "## 2.3 Создание функции потерь"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EY-k3eEs0f7f"
      },
      "source": [
        "2.3.1 Используя операции над матрицами и векторами из библиотеки `torch`, реализовать функцию потерь MSE:\n",
        "\n",
        "![](https://wikimedia.org/api/rest_v1/media/math/render/svg/e258221518869aa1c6561bb75b99476c4734108e)\n",
        "\n",
        "Создать полносвязный слой с 1 нейроном, прогнать через него батч `inputs` и посчитать значение MSE, трактуя вектор `y` как вектор правильных ответов."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "f9-wdj5Tz-br"
      },
      "outputs": [],
      "source": [
        "class MSELoss:\n",
        "  def forward(self, y_pred, y_true):\n",
        "    mse = ((y_pred - y_true)**2).mean()\n",
        "    return mse\n",
        "loss = MSELoss()\n",
        "linear_layer = torch.nn.Linear(4, 1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "NAyuDU9F1Vuz"
      },
      "outputs": [],
      "source": [
        "inputs = torch.tensor([[1, 2, 3, 2.5],\n",
        "                       [2, 5, -1, 2],\n",
        "                       [-1.5, 2.7, 3.3, -0.8]])\n",
        "\n",
        "y_true = torch.tensor([[2], [3], [4]])\n",
        "y_pred = linear_layer(inputs)\n",
        "mse_loss = loss.forward(y_pred, y_true)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"MSE Loss:\", mse_loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GbtlM17WxQPl",
        "outputId": "c85ab279-ad6b-4261-ec8e-3fe2299f1088"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE Loss: 33.128692626953125\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uaR7rILd1eWR"
      },
      "source": [
        "2.3.2 Используя операции над матрицами и векторами из библиотеки `torch`, реализовать функцию потерь Categorical Cross-Entropy:\n",
        "\n",
        "<img src=\"https://i.ibb.co/93gy1dN/Screenshot-9.png\" width=\"200\">\n",
        "\n",
        "Создать полносвязный слой с 3 нейронами и прогнать через него батч `inputs`. Полученный результат пропустить через функцию активации softmax. Посчитать значение CCE, трактуя вектор `y` как вектор правильных ответов."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "hQl8pJsT3HcF"
      },
      "outputs": [],
      "source": [
        "class CategoricalCrossentropyLoss:\n",
        "  def forward(self, y_pred, y_true):\n",
        "     softmax_pred = torch.softmax(y_pred, dim=1)\n",
        "     cce = -torch.log(softmax_pred.gather(1, y_true.view(-1, 1)))\n",
        "     return cce.mean()\n",
        "\n",
        "loss = CategoricalCrossentropyLoss()\n",
        "linear_layer = torch.nn.Linear(4, 3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "s7Qoupfo1ZGJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b13628af-701e-40fe-a3ca-2d3ae32efe01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-Entropy Loss: 1.9353302717208862\n"
          ]
        }
      ],
      "source": [
        "inputs = torch.tensor([[1, 2, 3, 2.5],\n",
        "                        [2, 5, -1, 2],\n",
        "                        [-1.5, 2.7, 3.3, -0.8]])\n",
        "y_true = torch.tensor([1, 0, 0])\n",
        "y_pred = linear_layer(inputs)\n",
        "cce_loss = loss.forward(y_pred, y_true)\n",
        "print(\"Cross-Entropy Loss:\", cce_loss.item())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fA6dbanf44_4"
      },
      "source": [
        "2.3.3 Модифицировать 2.3.1, добавив L2-регуляризацию.\n",
        "\n",
        "![](https://wikimedia.org/api/rest_v1/media/math/render/svg/d92ca2429275bfdc0474523babbafe014ca8b580)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ADsZxD-h4_Os"
      },
      "outputs": [],
      "source": [
        "class MSELossL2:\n",
        "  def __init__(self, lambda_):\n",
        "    # создать атрибут объекта alpha норма для функции потерь\n",
        "    pass\n",
        "\n",
        "  def data_loss(self, y_pred, y_true):\n",
        "    # <подсчет первого слагаемого из формулы>\n",
        "    pass\n",
        "\n",
        "  def reg_loss(self, layer):\n",
        "    # используйте атрибуты объекта layer, в которых хранятся веса слоя\n",
        "    # <подсчет второго слагаемого из формулы>\n",
        "    pass\n",
        "\n",
        "  def forward(self, y_pred, y_true):\n",
        "    return self.data_loss(y_pred, y_true) + self.reg_loss(y_pred, y_true)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w049ZSdR6qQi"
      },
      "source": [
        "## 2.4 Обратное распространение ошибки"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pBtCfSME9W7Q"
      },
      "source": [
        "2.4.1 Используя один нейрон и SGD (1 пример за шаг), решите задачу регрессии"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "4xmI-QJ66WAF"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import make_regression\n",
        "\n",
        "X, y, coef = make_regression(n_features=4, n_informative=4, coef=True, bias=0.5)\n",
        "X = torch.from_numpy(X).to(dtype=torch.float32)\n",
        "y = torch.from_numpy(y).to(dtype=torch.float32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KpPSPYSpD9Ey"
      },
      "source": [
        "[Граф вычислений для этой задачи](https://i.ibb.co/2dhDxZx/photo-2021-02-15-17-18-04.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "eYq46j8-UBP3"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fc1sXtGd_J-y"
      },
      "source": [
        "2.4.1.1 Реализуйте класс `SquaredLoss`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "llFigkqd_JRU"
      },
      "outputs": [],
      "source": [
        "class SquaredLoss:\n",
        "    def forward(self, y_pred, y_true):\n",
        "        # <реализовать логику MSE>\n",
        "        return (y_pred - y_true) ** 2\n",
        "\n",
        "    def backward(self, y_pred, y_true):\n",
        "        self.dinput = 2 * (y_pred - y_true)# df/dc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GY7ForfM97UQ"
      },
      "source": [
        "2.4.1.2. Модифицируйте класс `Neuron` из __2.1.1__:\n",
        "\n",
        "  1) Сделайте так, чтобы веса нейрона инициализировались из стандартного нормального распределения\n",
        "\n",
        "  2) Реализуйте расчет градиента относительно весов `weights` и `bias`"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "C8lX_BEzHvts"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "L0KqxPJU9kAN"
      },
      "outputs": [],
      "source": [
        "class Neuron:\n",
        "    def __init__(self, n_inputs):\n",
        "        # <создать атрибуты объекта weights и bias>\n",
        "        self.weights = torch.randn(n_inputs)\n",
        "        self.bias = torch.randn(1)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        # <реализовать логику нейрона>\n",
        "        self.inputs = inputs\n",
        "        return (inputs * self.weights).sum() + self.bias\n",
        "\n",
        "    def backward(self, dvalue):\n",
        "        # dvalue - значение производной, которое приходит нейрону от следующего слоя сети\n",
        "        # в данном случае это будет значение df/dc (созданное методом backwards у объекта MSELoss)\n",
        "        self.dweights = dvalue * self.inputs# df/dW\n",
        "        self.dinput =  dvalue * self.weights# df/wX\n",
        "        self.dbias = dvalue# df/db\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rKcO4zOLACxM"
      },
      "source": [
        "2.4.1.3 Допишите цикл для настройки весов нейрона\n",
        "\n",
        "[SGD](https://ru.wikipedia.org/wiki/%D0%A1%D1%82%D0%BE%D1%85%D0%B0%D1%81%D1%82%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%B8%D0%B9_%D0%B3%D1%80%D0%B0%D0%B4%D0%B8%D0%B5%D0%BD%D1%82%D0%BD%D1%8B%D0%B9_%D1%81%D0%BF%D1%83%D1%81%D0%BA)\n",
        "\n",
        "![](https://wikimedia.org/api/rest_v1/media/math/render/svg/dda3670f8a8996a0d3bf80856bb4a166cc8db6d4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "_g_FvwvmALJd"
      },
      "outputs": [],
      "source": [
        "n_inputs = X.shape[-1]\n",
        "learning_rate = 0.1 #  скорость обучения\n",
        "n_epoch = 100 #  количество эпох\n",
        "\n",
        "neuron = Neuron(n_inputs)\n",
        "loss = SquaredLoss()\n",
        "\n",
        "losses = []\n",
        "for epoch in range(100):\n",
        "    for x_example, y_example in zip(X, y):\n",
        "        # forward pass\n",
        "        y_pred = neuron.forward(x_example)# <прогон через нейрон>\n",
        "        curr_loss = loss.forward(y_pred, y_example) # <прогон через функцию потерь>\n",
        "        losses.append(curr_loss)\n",
        "\n",
        "        # backprop\n",
        "        # <вызов методов backward>\n",
        "        # обратите внимание на последовательность вызовов: от конца к началу\n",
        "        loss.backward(y_pred, y_example)\n",
        "        neuron.backward(loss.dinput)\n",
        "        # <шаг оптимизации для весов (weights и bias) нейрона>\n",
        "        neuron.weights -= learning_rate * neuron.dweights\n",
        "        neuron.bias -= learning_rate * neuron.dbias"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "losses[::1500]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_rVLxz1HBdcZ",
        "outputId": "484803d7-7aea-4b10-befa-9e60d8ed3442"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([12741.6787]),\n",
              " tensor([2.3283e-10]),\n",
              " tensor([0.]),\n",
              " tensor([0.]),\n",
              " tensor([2.3283e-10]),\n",
              " tensor([0.]),\n",
              " tensor([0.])]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebibge9VEgF7"
      },
      "source": [
        "2.4.2 Решите задачу 2.4.1, используя пакетный градиентный спуск"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "as-QeWSdOELd"
      },
      "source": [
        "Вычисления для этой задачи:\n",
        "[1](https://i.ibb.co/rmtQT6P/photo-2021-02-15-18-00-43.jpg)\n",
        "[2](https://i.ibb.co/NmCFVnQ/photo-2021-02-15-18-01-17.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dr9qq4H_J3zt"
      },
      "source": [
        "2.4.1.1 Модифицируйте класс `MSELoss` из __2.3.1__, реализовав расчет производной относительно предыдущего слоя с учетом того, что теперь работа ведется с батчами, а не с индивидуальными примерами\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L8wjk9iPMQ4x"
      },
      "outputs": [],
      "source": [
        "class MSELoss:\n",
        "  def forward(self, y_pred, y_true):\n",
        "    return # <реализовать логику MSE>\n",
        "\n",
        "  def backward(self, y_pred, y_true):\n",
        "    self.dinput = # df/dy^\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3fSHCEtJjX8"
      },
      "source": [
        "2.4.2.2. Модифицируйте класс `Neuron` из __2.4.1.2__:\n",
        "\n",
        "  1) Реализуйте метод `forward` таким образом, чтобы он мог принимать на вход матрицу (батч) с данными.\n",
        "\n",
        "  2) Реализуйте расчет градиента относительно весов `weights` и `bias` с учетом того, что теперь работа ведется с батчами, а не с индивидуальными примерами"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o_OpuAP0Jpz1"
      },
      "outputs": [],
      "source": [
        "class Neuron:\n",
        "  def __init__(self, n_inputs):\n",
        "    # <создать атрибуты объекта weights и bias>\n",
        "    pass\n",
        "\n",
        "  def forward(self, inputs):\n",
        "    return # <реализовать логику нейрона>\n",
        "\n",
        "  def backward(self, dvalue):\n",
        "    # dvalue - значение градиента, которое приходит нейрону от следующего слоя сети\n",
        "    # в данном случае это будет градиент L по y^ (созданный методом backwards у объекта MSELoss)\n",
        "    self.dweights = # df/dW\n",
        "    self.dbias = # df/db\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zO-NZrgKMBFx"
      },
      "source": [
        "2.4.2.3 Допишите цикл для настройки весов нейрона"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zqwm_7eqJim1"
      },
      "outputs": [],
      "source": [
        "n_inputs = # <размерность элемента выборки >\n",
        "learning_rate = 0.1 #  скорость обучения\n",
        "n_epoch = 100 #  количество эпох\n",
        "\n",
        "neuron = Neuron(n_inputs)\n",
        "loss = MSELoss()\n",
        "\n",
        "\n",
        "for epoch in range(100):\n",
        "    # forward pass\n",
        "    y_pred = # <прогон через нейрон>\n",
        "    curr_loss = # <прогон через функцию потерь>\n",
        "    losses.append(curr_loss)\n",
        "\n",
        "    # backprop\n",
        "    # <вызов методов backward>\n",
        "    # обратите внимание на последовательность вызовов: от конца к началу\n",
        "\n",
        "    # <шаг оптимизации для весов (weights и bias) нейрона>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16VtP159OdMk"
      },
      "source": [
        "2.4.3  Используя один полносвязный слой и  пакетный градиетный спуск, решите задачу регрессии из __2.4.1__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uj5febreSSZ7"
      },
      "source": [
        "2.4.3.1 Модифицируйте класс `Linear` из __2.1.4__. ([вычисление градиентов](https://i.ibb.co/kgVR6m6/photo-2021-02-15-21-30-28.jpg))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9zWuhaLdSB2_"
      },
      "outputs": [],
      "source": [
        "class Linear:\n",
        "  def __init__(self, n_features, n_neurons):\n",
        "    # <создать атрибуты объекта weights и biases>\n",
        "    pass\n",
        "\n",
        "  def forward(self, inputs):\n",
        "    return # <реализовать логику слоя>\n",
        "\n",
        "  def backward(self, dvalues):\n",
        "    self.dweights = # df/dW\n",
        "    self.dbiases = # df/db\n",
        "    self.dinputs = # df/dX"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3w1hT9MS_Lt"
      },
      "source": [
        "2.4.3.2 Создайте слой с одним нейроном. Используя класс MSELoss из 2.4.2, убедитесь, что модель обучается"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTkJV-F8TVuN"
      },
      "source": [
        "2.4.4 Используя наработки из 2.4, создайте нейросеть и решите задачу регрессии.\n",
        "\n",
        "Предлагаемая архитектура:\n",
        "1. Полносвязный слой с 10 нейронами\n",
        "2. Активация ReLU\n",
        "3. Полносвязный слой с 1 нейроном"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "axUjpPz-SvS1"
      },
      "outputs": [],
      "source": [
        "X = torch.linspace(-1, 1, 100).view(-1, 1)\n",
        "y = X.pow(2) + 0.2 * torch.rand(X.size())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LXoiNxkpTziV"
      },
      "outputs": [],
      "source": [
        "class Activation_ReLU:\n",
        "  def forward(self, inputs):\n",
        "    self.inputs = inputs\n",
        "    self.output = inputs.clip(min=0)\n",
        "    return self.output\n",
        "\n",
        "  def backward(self, dvalues):\n",
        "    self.dinputs = dvalues.clone()\n",
        "    self.dinputs[self.inputs <= 0] = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tXhspwW6T44T"
      },
      "outputs": [],
      "source": [
        "# создание компонентов сети\n",
        "# fc1 =\n",
        "# relu1 =\n",
        "# fc2 =\n",
        "\n",
        "loss = MSELoss()\n",
        "lr = 0.02\n",
        "\n",
        "ys = []\n",
        "for epoch in range(2001):\n",
        "  # <forward pass>\n",
        "  # fc1 > relu1 > fc2 > loss\n",
        "\n",
        "  data_loss = # <прогон через функцию потерь>\n",
        "\n",
        "  if epoch % 200 == 0:\n",
        "    print(f'epoch {epoch} mean loss {data_loss}')\n",
        "    ys.append(out)\n",
        "\n",
        "  # <backprop>\n",
        "  # loss > fc2 > relu1 > fc1\n",
        "\n",
        "  # <шаг оптимизации для fc1>\n",
        "\n",
        "  # <шаг оптимизации для fc2>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kpKi0OfoUkwk"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, axs = plt.subplots(len(ys), 1, figsize=(10, 40))\n",
        "for ax, y_ in zip(axs, ys):\n",
        "  ax.scatter(X.numpy(), y.numpy(), color = \"orange\")\n",
        "  ax.plot(X.numpy(), y_.numpy(), 'g-', lw=3)\n",
        "  ax.set_xlim(-1.05, 1.5)\n",
        "  ax.set_ylim(-0.25, 1.25)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}